# SAM3 Adaptive Ad System

An AI-powered adaptive advertising platform that uses **SAM 3** (Segment Anything Model 3), **CLIP**, and **Stable Diffusion 1.5** to create intelligent, engagement-driven product advertisements.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Flask](https://img.shields.io/badge/Flask-3.0.0-green.svg)
![React](https://img.shields.io/badge/React-18-61DAFB.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## Overview

This system revolutionizes digital advertising by combining cutting-edge AI models to:
- **Automatically segment products** from images using SAM 3
- **Analyze visual semantics** with CLIP to understand product context
- **Generate contextual backgrounds** using Stable Diffusion 1.5
- **Track user engagement** in real-time with heatmap visualization
- **Adapt layouts dynamically** based on user interaction patterns

## Key Features

### ðŸŽ¯ AI-Powered Product Segmentation
- **SAM 3 Integration**: Text-prompted automatic product extraction from images
- **Intelligent Masking**: Precise product boundary detection
- **Multi-view Generation**: Automatic creation of cropped and full product views

### ðŸŽ¨ Smart Background Generation
- **CLIP Analysis**: Semantic understanding of product images
- **SD 1.5 Backgrounds**: AI-generated abstract backgrounds that complement products
- **Mood Matching**: Color-aware background generation based on product tones

### ðŸ“Š Real-Time Engagement Analytics
- **Click Tracking**: Monitor user interactions with products
- **Hover Analysis**: Measure browsing behavior and interest duration
- **Heatmap Visualization**: Visual representation of engagement hotspots
- **Session Management**: Per-user session tracking and analytics

### ðŸ§  Adaptive Layout Optimization
- **AI-Driven Composition**: Automatic product placement optimization
- **Engagement-Based Adaptation**: Layouts adjust based on user behavior
- **Hotspot-Aware Positioning**: Products positioned near engagement centers

### ðŸš€ Production-Ready Architecture
- **Flask REST API**: Robust backend with CORS support
- **React Frontend**: Modern, responsive single-page application
- **Scalable Design**: In-memory data structures with easy database integration
- **Comprehensive Error Handling**: Graceful fallbacks and detailed logging

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React)                         â”‚
â”‚  - Product Upload Interface                                 â”‚
â”‚  - Interactive Ad Canvas with Zoom/Pan                      â”‚
â”‚  - Real-Time Heatmap Visualization                          â”‚
â”‚  - Engagement Analytics Dashboard                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†• HTTP/REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Backend (Flask)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   SAM 3      â”‚â†’ â”‚    CLIP      â”‚â†’ â”‚   SD 1.5     â”‚      â”‚
â”‚  â”‚ Segmentation â”‚  â”‚   Analysis   â”‚  â”‚  Background  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Engagement Tracker â†’ AI Analyzer â†’ Layout Optimizer â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Technology Stack

### Backend
- **Python 3.8+**: Core programming language
- **Flask 3.0.0**: Web framework for REST API
- **PyTorch 2.7.0**: Deep learning framework
- **SAM 3**: Product segmentation (Meta's Segment Anything Model 3)
- **CLIP**: Vision-language understanding (OpenAI)
- **Stable Diffusion 1.5**: Background image generation
- **Pillow**: Image processing and manipulation
- **NumPy**: Numerical computations

### Frontend
- **React 18**: UI framework
- **Vanilla CSS3**: Styling with animations
- **Babel**: JSX transpilation (browser-based)

### Models
- **SAM 3**: Text-prompted object segmentation
- **CLIP ViT-B/32**: Image-text similarity analysis
- **SD 1.5**: High-quality image generation

## Installation

### Prerequisites
- Python 3.8 or higher
- CUDA-compatible GPU (recommended for best performance)
- 8GB+ RAM
- HuggingFace account (for SAM 3 model access)

### Quick Start

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/sam3-adaptive-ads.git
cd sam3-adaptive-ads
```

2. **Run setup script**
```bash
chmod +x *.sh
./setup.sh
```

This will:
- Install Python dependencies
- Check for SAM 3 installation
- Set up folder structure

3. **Configure SAM 3 (Required for full functionality)**
```bash
# Clone SAM 3 repository
cd ..
git clone https://github.com/facebookresearch/sam3.git

# Authenticate with HuggingFace
pip install huggingface_hub
huggingface-cli login
# Enter your HuggingFace token

# Install SAM 3
cd sam3
pip install -e .
cd ../sam3-adaptive-ads
```

4. **Configure Stable Diffusion 1.5**
```bash
# Download SD 1.5 checkpoint or set path in server.py
# Default path: /path/to/v1-5-pruned-emaonly-fp16.safetensors
# Update SD15_PATH environment variable or edit server.py line 22-25
```

5. **Start the system**
```bash
./start.sh
```

6. **Open the frontend**
- Navigate to `http://localhost:5000` to verify backend is running
- Open `frontend/index.html` in your web browser

## Usage

### Uploading Products

1. **Click "Choose Product Image"** in the sidebar
2. **Select a product image** from your computer
3. **Enter a text prompt** (e.g., "red sneaker", "leather jacket", "coffee mug")
4. **Click "Segment & Upload"**
5. The system will:
   - Segment the product using SAM 3
   - Extract the product from background
   - Store it in the product library

### Interacting with the Canvas

- **Click** on products to indicate interest
- **Hover** over products to browse
- **Click on empty space** to generate variations
- **Zoom** in/out using the zoom controls
- **Drag** to pan around the canvas

### Understanding AI Behavior

The system analyzes engagement every 2 seconds:

**High Engagement (45+ seconds active time)**
- Triggers background generation
- Uses CLIP to analyze product context
- Generates 3 AI backgrounds using SD 1.5
- Creates compositions with heatmap-aware positioning

**Composition Generation**
- Analyzes dominant colors from original image
- Selects abstract background styles via CLIP
- Generates backgrounds with SD 1.5
- Composites product with shadow effects
- Positions based on user interaction hotspots

## API Endpoints

### `POST /api/upload`
Upload and segment product image

**Request:**
```
Content-Type: multipart/form-data
- file: Image file
- product_name: Text prompt for segmentation
```

**Response:**
```json
{
  "product_id": "abc123",
  "product": {
    "id": "abc123",
    "name": "red sneaker",
    "views": {
      "original": {"url": "...", "base64": "..."},
      "cropped": {"url": "...", "base64": "..."}
    },
    "segmentation": {
      "box": [x1, y1, x2, y2],
      "score": 0.95
    }
  }
}
```

### `GET /api/products`
List all uploaded products

### `POST /api/track`
Track user interaction

**Request:**
```json
{
  "session_id": "session_xxx",
  "type": "click|hover|hover_canvas",
  "data": {
    "x": 150,
    "y": 200,
    "product_id": "abc123",
    "duration": 1500
  }
}
```

### `POST /api/analyze`
Analyze engagement and get compositions

**Request:**
```json
{
  "session_id": "session_xxx",
  "layout": [...]
}
```

**Response:**
```json
{
  "action": "new_compositions|continue",
  "compositions": [
    {
      "url": "...",
      "base64": "...",
      "prompt": "abstract background, smooth gradient...",
      "product_id": "abc123"
    }
  ],
  "reasoning": ["Generated new SD1.5 backgrounds..."]
}
```

### `POST /api/heatmap`
Get heatmap data for visualization

### `GET /api/stats`
Get overall system statistics

## Configuration

### Environment Variables

```bash
# SD 1.5 checkpoint path
export SD15_PATH="/path/to/v1-5-pruned-emaonly-fp16.safetensors"

# CLIP cache directory
export CLIP_CACHE_DIR="~/.cache/clip"

# CLIP model variant
export CLIP_NAME="ViT-B/32"
```

### Backend Configuration (server.py)

```python
# Lines 19-36: Model configuration
DEVICE = "cuda"  # or "cpu"
SD15_PATH = "..."
BG_WIDTH, BG_HEIGHT = 512, 512  # Background size
```

### Frontend Configuration (frontend/index.html)

```javascript
// Line 59: API endpoint
const API_BASE = 'http://localhost:5000/api';

// Line 86: Analysis interval
setInterval(() => analyzeEngagement(), 2000);  // 2 seconds
```

## Project Structure

```
sam3-adaptive-ads/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.py              # Flask backend (577 lines)
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ uploads/              # Original uploaded images
â”‚   â”œâ”€â”€ processed/            # Processed product images
â”‚   â””â”€â”€ compositions/         # Generated compositions
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html            # React SPA
â”œâ”€â”€ setup.sh                  # Installation script
â”œâ”€â”€ start.sh                  # Startup script
â”œâ”€â”€ stop.sh                   # Shutdown script
â”œâ”€â”€ test.sh                   # System validation
â””â”€â”€ README.md                 # This file
```

## How It Works

### 1. Product Upload & Segmentation
```python
# User uploads image with text prompt
segment_with_sam3(image, "red sneaker")
â†’ SAM 3 segments product from background
â†’ Returns mask, bounding box, confidence score
â†’ Extract product as RGBA with transparency
```

### 2. CLIP Analysis
```python
# Analyze product and original image semantics
clip_best_background_prompts(original_img, product_img, avg_rgb)
â†’ Extract CLIP features from original image
â†’ Compare with abstract scene categories
â†’ Identify dominant colors
â†’ Generate 3 complementary prompts
```

### 3. Background Generation
```python
# Generate abstract backgrounds with SD 1.5
sd15_generate_background("abstract background, smooth gradient...")
â†’ SD 1.5 generates 512x512 background
â†’ Uses color-matched prompts from CLIP
â†’ Negative prompts filter low quality
```

### 4. Composition
```python
# Composite product onto background
compose_product_on_bg(product_rgba, bg, hotspot_xy)
â†’ Resize product to 80% of canvas
â†’ Create soft shadow for depth
â†’ Position based on heatmap centroid
â†’ Blend with smooth alpha compositing
```

### 5. Engagement Tracking
```javascript
// Frontend tracks all interactions
onClick/onHover â†’ POST /api/track
â†’ Backend stores in session data
â†’ Frontend visualizes as heatmap
â†’ Every 2s: POST /api/analyze
```

## Performance

### Image Processing
- **Product Segmentation**: ~30-50ms (GPU) / ~200-500ms (CPU)
- **CLIP Analysis**: ~50-100ms
- **SD 1.5 Generation**: ~2-5s per background (GPU)
- **Composition**: ~100-200ms per image

### API Response Times
- Upload & Segment: 1-3 seconds
- Track Interaction: <50ms
- Analyze Engagement: <100ms (no generation) / 6-15s (with generation)
- Heatmap Data: <20ms

### Resource Usage
- **Memory**: ~4-6GB (with all models loaded)
- **GPU VRAM**: ~3-5GB (recommended)
- **Disk**: ~10GB (for model checkpoints)

## Troubleshooting

### SAM 3 Import Errors
```bash
# Ensure SAM 3 is installed
cd sam3 && pip install -e .

# Verify HuggingFace authentication
huggingface-cli whoami
```

### CUDA Out of Memory
```python
# Edit server.py line 84-88
# Change dtype to torch.float32 (uses more VRAM but more compatible)
dtype = torch.float32
```

### Port 5000 Already in Use
```bash
./stop.sh  # Kill existing process
# Or manually:
lsof -ti:5000 | xargs kill -9
```

### Frontend Not Connecting
- Verify backend is running: `curl http://localhost:5000`
- Check browser console for CORS errors
- Ensure API_BASE in index.html points to correct URL

## Deployment

### Docker Deployment
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY backend/requirements.txt .
RUN pip install -r requirements.txt
COPY backend/ ./backend/
COPY frontend/ ./frontend/
CMD ["python", "backend/server.py"]
```

### Cloud Deployment
- **AWS**: EC2 with GPU (p3.2xlarge) + S3 for images
- **Google Cloud**: Compute Engine with GPU + Cloud Storage
- **Azure**: GPU VM + Blob Storage

### Production Considerations
- Add authentication/authorization
- Implement rate limiting
- Use Redis for session storage
- Set up CDN for static assets
- Enable HTTPS
- Add database for persistent storage
- Implement image compression
- Add monitoring and logging

## Future Enhancements

- [ ] Multi-product composition support
- [ ] A/B testing framework
- [ ] Video ad generation
- [ ] Advanced analytics dashboard
- [ ] Machine learning for click prediction
- [ ] Integration with ad platforms (Google Ads, Facebook Ads)
- [ ] Mobile-responsive design
- [ ] Real-time collaboration features
- [ ] Export to various ad formats
- [ ] Automated campaign optimization

## Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- **Meta AI** for SAM 3 (Segment Anything Model 3)
- **OpenAI** for CLIP
- **Stability AI** for Stable Diffusion
- **HuggingFace** for model hosting and diffusers library

## Citation

If you use this project in your research, please cite:

```bibtex
@software{sam3_adaptive_ads,
  title={SAM3 Adaptive Ad System},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/sam3-adaptive-ads}
}
```

## Contact

For questions, issues, or collaboration opportunities:
- GitHub Issues: [https://github.com/yourusername/sam3-adaptive-ads/issues](https://github.com/yourusername/sam3-adaptive-ads/issues)
- Email: your.email@example.com

## Changelog

### Version 1.0.0 (2024-12-29)
- Initial release
- SAM 3 integration for product segmentation
- CLIP-based semantic analysis
- SD 1.5 background generation
- Real-time engagement tracking
- Adaptive composition system
- Complete REST API
- React-based frontend

---

**Built with AI** - Leveraging the power of SAM 3, CLIP, and Stable Diffusion for next-generation advertising.
